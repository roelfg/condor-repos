MachineOwner = physics
StartJobs = True
## NUM_CPUS based on heira (if defined), otherwise on facter
NUM_CPUS = 2

DETECTED_CPUS = $NUM_CPUS

# custom machine attributes for job matching
# e.g. queues with ARC CE (using condor_requirements=" && NORDUGRID_QUEUE)"
STARTD_ATTRS = MachineOwner, StartJobs

# custom job attributes for job reporting/monitoring
STARTD_JOB_ATTRS = MemoryUsage

## Permanent way of stopping jobs from starting
STARTD.SETTABLE_ATTRS_ADMINISTRATOR = StartJobs
ENABLE_PERSISTENT_CONFIG = TRUE
PERSISTENT_CONFIG_DIR = /etc/condor/persistent

## Healthcheck
STARTD_CRON_JOBLIST = $(STARTD_CRON_JOBLIST) WN_HEALTHCHECK
STARTD_CRON_WN_HEALTHCHECK_EXECUTABLE = /usr/local/bin/healthcheck_wn_condor
STARTD_CRON_WN_HEALTHCHECK_PERIOD = 1m
STARTD_CRON_WN_HEALTHCHECK_MODE = periodic
STARTD_CRON_WN_HEALTHCHECK_RECONFIG = false
STARTD_CRON_WN_HEALTHCHECK_KILL = true

## When is this node willing to run jobs?
START = (NODE_IS_HEALTHY =?= True) && (StartJobs =?= True)
## Some users can also run jobs if the node is not healthy / startjobs is false.
START = ($(START)) || ( TARGET.Owner =?= "freyermu" || TARGET.Owner =?= "wiene" )
SUSPEND = FALSE
CONTINUE = TRUE
WANT_SUSPEND = $(SUSPEND)
KILL = FALSE

## When to nicely stop a job?
## (as opposed to killing it instantaneously)
PREEMPT = FALSE
## Overcommit memory and  quantize the detected memory
MEMORY = 1.0 * quantize( $(DETECTED_MEMORY), 1000 )

## Partitionable slots
NUM_SLOTS = 1
SLOT_TYPE_1               = cpus=100%,mem=100%,auto
NUM_SLOTS_TYPE_1          = 1
SLOT_TYPE_1_PARTITIONABLE = TRUE

## Without this lots of memory (& hence job slots) will be wasted
MODIFY_REQUEST_EXPR_REQUESTMEMORY = quantize(RequestMemory,100)
## Disable preemption by machine RANK by ranking all jobs equally
RANK = 0

## Niceness of user jobs
JOB_RENICE_INCREMENT = 10

## Since we don't use preemption, make sure slots aren't permanently taken by specific users
CLAIM_WORKLIFE = 1200

## Allow jobs time to finish if they need to be preempted (should be same as max walltime allowed)
MAXJOBRETIREMENTTIME = $(HOUR) * 24 * 3

## Update collector at random intervals
UPDATE_INTERVAL = $RANDOM_INTEGER(230, 370)
MASTER_UPDATE_INTERVAL = $RANDOM_INTEGER(230, 370)

## Special environment setup
STARTER_JOB_ENVIRONMENT = "SINGULARITY_HOME=/jwd SINGULARITY_NOHOME=true SINGULARITY_DISABLE_CACHE=true SHELL=/bin/bash PATH=/usr/sue/bin:/usr/local/bin:/bin:/usr/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin"

## Location of scratch directories
EXECUTE = /pool/condor

## Writable scratch directories bind mounted in scratch, e.g. for docker / singularity containers.
## Auto-deleted after the job exits.
MOUNT_UNDER_SCRATCH = /tmp

## Make sure jobs have independent PID namespaces
USE_PID_NAMESPACES = false

## Logs
MAX_MASTER_LOG = 104857600
MAX_NUM_MASTER_LOG = 10

MAX_STARTD_LOG = 104857600
MAX_NUM_STARTD_LOG = 10

# Enable CGROUP
BASE_CGROUP = htcondor
CGROUP_MEMORY_LIMIT_POLICY = hard

## Debugging
#STARTD_DEBUG = D_COMMAND D_FULLDEBUG

##  This macro determines what daemons the condor_master will start and keep its watchful eyes on.
##  The list is a comma or space separated list of subsystem names
DAEMON_LIST = MASTER, STARTD

