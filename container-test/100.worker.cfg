# Copyright 2019 Karlsruhe Institute of Technology KIT
#
# SPDX-License-Identifier: GPL-3.0-or-later

# HTCondor configuration:
# StartD Daemon (Worker Node)

UID_DOMAIN	= $(FULL_HOSTNAME)

DAEMON_LIST     = $(DAEMON_LIST), \
                  StartD

# Job handling
PREEMPT         = FALSE
SUSPEND         = FALSE
CONTINUE        = FALSE
KILL            = FALSE
WANT_SUSPEND    = FALSE
WANT_VACATE     = TRUE


# Who may start/stop/restart/userprio/... via Condor commsnds
ALLOW_ADMINISTRATOR = $(ALLOW_ADMINISTRATOR), cobald@physik.uni-bonn.de/131.220.166.41
# Who may edit via condor_config_val - please prefer editing the configs!
ALLOW_CONFIG = $(ALLOW_ADMINISTRATOR), condor@*/$(FULL_HOSTNAME)
# Who may control condor locally?
ALLOW_OWNER = condor@*/$(FULL_HOSTNAME), condor@*/$(IP_ADDRESS), $(ALLOW_ADMINISTRATOR)
# Who may act as a daemon?
ALLOW_DAEMON = $(ALLOW_DAEMON), condor@$(FULL_HOSTNAME), condor_pool@$(FULL_HOSTNAME)
# Who may query information from the system?
ALLOW_READ = *
# Who may add information to the system?
ALLOW_WRITE = $(ALLOW_WRITE)

# Cloud and TARDIS attributes
STARTD_ATTRS = $(STARTD_ATTRS) START_OVERLAY_BATCH_JOBS ACCEPTED_VO Contractor Cloud TardisDroneUuid
TardisDroneUuid = "$ENV(TardisDroneUuid)"

# Modify STARTD_NAME since multiple drones can run on the same host
STARTD_NAME = $ENV(TardisDroneUuid)

# Limit CPU, Memory and Disk to the capacity of the pilot
NUM_CPUS = $ENV(TardisDroneCores)
MEMORY = $ENV(TardisDroneMemory)
DISK = $ENV(TardisDroneDisk)

# Auto shutdown after 10 minutes of idle time
STARTD_NOCLAIM_SHUTDOWN = 10 * $(MINUTE)

# Where to find condor tools
RELEASE_DIR = /usr
# Since condor version installed in container is different from condor version on worker nodes
LIBEXEC = $(RELEASE_DIR)/libexec/condor_pilot

# Adjust shared port for the overlay batch system, since standard one is already in use. Let condor
# decide on the port to use 
SHARED_PORT_PORT = 0

# Use proxy for GSI auth
GSI_DAEMON_DIRECTORY=$ENV(JWD)
GSI_DAEMON_NAME = /C=DE/O=GermanGrid/OU=KIT/CN=cloud-htcondor.gridka.de,/C=DE/O=GermanGrid/OU=UniBonn/CN=Robot - Bonn COBalD TARDIS Drone Service
GSI_DAEMON_PROXY = $ENV(JWD)/proxy
GRIDMAP = /etc/condor/grid_mapfile
#GSI_DAEMON_TRUSTED_CA_DIR=/etc/grid-security/certificates
GSI_DAEMON_TRUSTED_CA_DIR=/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/etc/grid-security-emi/certificates

# Include resource specific configuration
include command : /usr/local/bin/get-condor-cobald-config

# Filter accepted jobs by VO.
ACCEPTED_VO = "$ENV(VO)"
START = $(START) && (TARGET.x509UserProxyVOName=?=MY.ACCEPTED_VO) && (START_OVERLAY_BATCH_JOBS =?= True)

# Only accept jobs matching the core count of the drone.
START = ( $(START) ) && ifThenElse(TARGET.RequestCpus isnt undefined,MY.Cpus > 0 && TARGET.RequestCpus == MY.Cpus,1 == MY.Cpus)

# Adjust starter environment as passed in by the pilot startup script.
STARTER_JOB_ENVIRONMENT = "$(STARTER_JOB_ENVIRONMENT) $ENV(CONDOR_STARTER_JOB_ENVIRONMENT)"

# Export CPU efficiency (takes used child slots, exports their CPUsUsage and then re-exports the average).
# Only works starting with HTCondor 8.7.
STARTD_PARTITIONABLE_SLOT_ATTRS = $(STARTD_PARTITIONABLE_SLOT_ATTRS), CPUsUsage
AverageCPUsUsage = Sum(My.ChildCPUsUsage)/Sum(My.ChildCPUs)
STARTD_ATTRS = $(STARTD_ATTRS), AverageCPUsUsage

# Accounting information
# Dummy scaling 1.0 for now.
ApelScaling = 1.0
STARTD_ATTRS = $(STARTD_ATTRS), ApelScaling

# Use job wrapper which enforces that a login shell is used also for batch jobs.
USER_JOB_WRAPPER = $(LIBEXEC)/jobwrapper.sh
